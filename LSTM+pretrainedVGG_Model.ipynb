{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Lambda, Flatten, Reshape, Dropout\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D,Cropping2D,ZeroPadding2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D, MaxPool2D\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.layers import Input\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "import keras\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDF5_PATH = \"./Data_10sec.hdf5\"\n",
    "\n",
    "hdf = h5py.File(HDF5_PATH, \"r\")\n",
    "pframes = hdf[ \"Validation_Set/Total_Video\"]\n",
    "plt.imshow(pframes[44], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the total samples in each set\n",
    "train_len = len(hdf[\"Training_Set/Total_Gaze\"])\n",
    "test_len = len(hdf[\"Testing_Set/Total_Gaze\"])\n",
    "val_len = len(hdf[\"Validation_Set/Total_Gaze\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(set_name,batch_size,timesteps):\n",
    "    \n",
    "    hdf = h5py.File(HDF5_PATH, \"r\")\n",
    "    \n",
    "    pgaze = hdf[set_name +\"/Total_Gaze\"][:,:,1:3]\n",
    "    pframes = hdf[set_name +\"/Total_Video\"]\n",
    "    pLabels = hdf[set_name +\"/Total_Label\"][:,1:10]\n",
    "\n",
    "    len_train = pgaze.shape[0]\n",
    "    randomBatchOrder = list(range(len_train-timesteps))\n",
    "    while True:\n",
    "        #np.random.shuffle(randomBatchOrder) \n",
    "        for i in range(0, (len_train // (batch_size))-1):\n",
    "            gaze = []\n",
    "            frames = []\n",
    "            labels = []\n",
    "            for j in range (batch_size): # this loop fetches batch_size number of samples, each sample having timestep samples\n",
    "                idx = randomBatchOrder[i*batch_size+j]\n",
    "                \n",
    "                g = pgaze[idx:idx+timesteps]\n",
    "                gaze.append(g)\n",
    "                f = pframes[idx:idx+timesteps]\n",
    "                frames.append(f)\n",
    "                l = pLabels[idx+timesteps]\n",
    "                labels.append(l)\n",
    "\n",
    "            yield [np.array(gaze).reshape(batch_size, -1, 2,1), np.array(frames)], np.array(labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "timesteps = 60//5\n",
    "batch_size = 15\n",
    "epochs = 150\n",
    "NUM_CLASSES =9\n",
    "g = myGenerator('Training_Set', batch_size, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x,y  = next(g)\n",
    "i = 3\n",
    "for idx in range(timesteps):\n",
    "    img = x[1][i][idx]\n",
    "    plt.imshow(img)\n",
    "    gaze = x[0][idx]\n",
    "    plt.scatter(gaze[:,0]*img.shape[1], gaze[:,1]*img.shape[0], c=\"r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazeShape = x[0].shape\n",
    "imgShape = x[1].shape\n",
    "\n",
    "print(y.shape,gazeShape,imgShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    config = tf.ConfigProto(log_device_placement = True, allow_soft_placement = True)\n",
    "    config.gpu_options.allow_growth=True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    \n",
    "    with tf.Session(config=config):\n",
    "        tf.get_default_graph()\n",
    "        \n",
    "        # Broadcast progress to the tensorboard.\n",
    "        readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "        file_name = \"Team3_\" + readable_timestamp\n",
    "        print(file_name)\n",
    "        tensorboardFolder = \"/srv/share/tensorboardfiles/\" + file_name\n",
    "        \n",
    "        \n",
    "        optimizer=optimizers.Adam(lr = 0.0001)\n",
    "                \n",
    "        cnn_base = VGG19(input_shape=(imgShape[2], imgShape[3], imgShape[4]), weights=\"imagenet\", include_top=False)\n",
    "        cnn_out = GlobalAveragePooling2D()(cnn_base.output)\n",
    "        cnn = Model(inputs=cnn_base.input, outputs=cnn_out) #VGG19 pretrained model\n",
    "        for layer in cnn.layers: \n",
    "            layer.trainable = False   \n",
    "            \n",
    "        scene_input = Input(shape=(timesteps,imgShape[2], imgShape[3], imgShape[4]), name='scene_input')\n",
    "        scene_frames = TimeDistributed(cnn)(scene_input) #Timedistributed wrapper around VGG19 model\n",
    "        scene_flatten_TD = TimeDistributed(Flatten())(scene_frames)\n",
    "        scene_flatten = LSTM(50, dropout=0.7, recurrent_dropout=0.7)(scene_flatten_TD)\n",
    "        \n",
    "        gaze_input = Input(shape = (gazeShape[1], gazeShape[2],gazeShape[3]),name = \"gaze_input\") #reshaped gaze input\n",
    "        gaze_Conv2D_1 = Conv2D(filters = 64, kernel_size = (4,1), activation ='relu',\n",
    "                               kernel_initializer= 'glorot_normal')(gaze_input)\n",
    "        gaze_Maxpool = MaxPool2D(pool_size=(10,1))(gaze_Conv2D_1)\n",
    "       \n",
    "        gaze_Conv2D_2 = Conv2D(filters = 32, kernel_size = (4,1), activation ='relu',\n",
    "                               kernel_initializer= 'glorot_normal')(gaze_Maxpool)\n",
    "        gaze_Maxpool2 = MaxPool2D(pool_size=(10,1))(gaze_Conv2D_2)\n",
    "        \n",
    "        gaze_flatten = Flatten()(gaze_Maxpool2)\n",
    "        Merge = Concatenate()([gaze_flatten, scene_flatten]) # concatenate intermediate outputs from gaze and scene model\n",
    "\n",
    "        Dense1 = Dense(256,activation='relu',kernel_regularizer=regularizers.l2(0.01))(Merge)\n",
    "        Dense1 = Dropout(0.3)(Dense1)\n",
    "        Dense2 = Dense(128,activation='relu',kernel_regularizer=regularizers.l2(0.01))(Dense1)\n",
    "        Dense2 = Dropout(0.3)(Dense2)\n",
    "        Out = Dense(NUM_CLASSES, activation='sigmoid')(Dense2) # final output layer\n",
    "            \n",
    "            # Multi-task loss\n",
    "        def multitask_loss(y_true, y_pred):\n",
    "            # Avoid divide by 0\n",
    "            y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "            return K.mean(K.sum(- y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred), axis=1))\n",
    "        \n",
    "       \n",
    "        Combined_model = Model(inputs=[gaze_input, scene_input], outputs=[Out])\n",
    "        Combined_model.compile(optimizer=optimizer, loss=multitask_loss, metrics = [multitask_loss, \"acc\"])\n",
    "        Combined_model.summary()\n",
    "        \n",
    "        callbacks = [\n",
    "            ModelCheckpoint(str(Path.home()) + \"/models/\"+ file_name + \".{epoch:04d}-{val_loss:.2f}.h5\",\n",
    "                            monitor='val_acc',\n",
    "                            verbose=0,\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=False\n",
    "                           ),\n",
    "            LoggingTensorBoard(settings_str_to_log=config,\n",
    "                               log_dir=tensorboardFolder,\n",
    "                               histogram_freq=0,\n",
    "                               write_graph=True,\n",
    "                               write_images=True,\n",
    "                               update_freq='epoch'\n",
    "                              ),\n",
    "            # Learning Rate\n",
    "            ReduceLROnPlateau(monitor='val_loss',\n",
    "                              patience=10,\n",
    "                              verbose=1,\n",
    "                              factor=0.9,\n",
    "                              min_lr=0.00001),\n",
    "        ]\n",
    "\n",
    "        history = Combined_model.fit_generator(myGenerator(\"Training_Set\",batch_size,timesteps),\n",
    "                                steps_per_epoch=train_len // batch_size,\n",
    "                                epochs=epochs,\n",
    "                                verbose=1,\n",
    "                                validation_data= myGenerator(\"Testing_Set\",batch_size,timesteps),\n",
    "                                validation_steps=test_len // batch_size,\n",
    "                                callbacks = callbacks)\n",
    "        \n",
    "        result = Combined_model.predict_generator(myGenerator(\"Validation_Set\",batch_size,timesteps),\n",
    "                                                steps=val_len // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ground truth labels of validation set\n",
    "val_label = hdf[\"Validation_Set/Total_Label\"][4:2974,1:10]\n",
    "print(val_label.shape)\n",
    "\n",
    "#Convert the probabilities to predicted label vectors\n",
    "result[result>=0.5] =1\n",
    "result[result<0.5] =0\n",
    "print(hamming_loss(val_label,result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize history for loss\n",
    "plt.plot(history.history['multitask_loss'])\n",
    "plt.plot(history.history['val_multitask_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix of each activity\n",
    "for activity in range(10):\n",
    "    print(\"Activity \",activity+1,confusion_matrix(val_label[:,activity], result[:,activity]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix in percentage\n",
    "for val in range(10):\n",
    "    print(\"Activity\", val+1) \n",
    "    confusion_mat = confusion_matrix(val_label[:,val], result[:,val])\n",
    "    mat_toarray = np.asarray(confusion_mat)\n",
    "    array_sum = np.sum(mat_toarray)\n",
    "    print((mat_toarray/array_sum)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
